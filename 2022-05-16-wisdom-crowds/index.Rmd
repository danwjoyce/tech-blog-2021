---
title: Three Heads are Better Than One
author: Dan W. Joyce
date: '2022-05-16'
slug: wisdom-of-crowds
categories: [simulation]
tags: [mixture of experts]
subtitle: 'The Wisdom of Crowds and MDTs'
summary: ''
draft: true
lastmod: '2022-05-15T22:00:06Z'
featured: yes
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []

output:
  blogdown::html_page:
     number_sections: true
     toc: true

header-includes: \usepackage{amsmath}

bibliography: [./biblio.bib]

---

\newcommand{\Var}{\mathrm{Var}}
\newcommand\ci{\perp\!\!\!\perp}


```{r setup, include=FALSE}
rm( list = ls() )
knitr::opts_chunk$set(echo = TRUE)

## Some globals to control execution of chunks because the simulations are
## very time consuming
RUN_SIMS <- FALSE


library(ggplot2)
library(gridExtra)
library(kableExtra)
library(latex2exp)
library(reshape2)
library(viridisLite)
library( RcppAlgos )

# globals for presentation
basictheme <- theme_minimal() + 
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        plot.title = element_text(size = rel(1.25), face = "bold", hjust = 0.5 ))
```

```{r, eval = TRUE, echo = FALSE}

buildVotingMatrix <- function(N) {
  l <- rep(list(0:1), N)
  V <- expand.grid(l)
  names(V) <- paste0( "v", seq(1:N) )
  return(V)
}

probVotingProfile <- function( v, p ) {
  pr.v_i <- 1
  for( i in 1:length( v ) ) {
    pr.v_i <- pr.v_i *
                ( p[i]^v[i] ) * ( 1-p[i] )^(1-v[i] )
  }
  return( as.numeric( pr.v_i ) )
}

computeVotingProfileProb <- function( V, p ) {
  pr.v <- rep(NA, nrow(V))
  N <- ncol(V)
  for( i in 1:nrow(V) ) {
    pr.v[i] <- probVotingProfile( V[i,1:N], p )
  }
  
  return( pr.v ) 
}

indexMajority <- function( V ) {
  N <- ncol(V)
  M <- floor( N/2 ) + 1
  N.ones <- rowSums( V )
  return( which( N.ones >= M ) )
}
  
```


# Introduction
We often make decisions in teams on the assumption that we obtain more reliable decision making when we use the consensus of a group of people -- or to quote C.S. Lewis, "Two heads are better than one, not because either is infallible, but because they are unlikely to go wrong in the same direction".  This is related to the [wisdom of crowds](https://en.wikipedia.org/wiki/Wisdom_of_the_crowd) and is not without controversy.  In healthcare, the multi-disciplinary team (MDT) is central to decision making when there is uncertainty and/or there is a need for multiple expertise; we assemble a group of professionals with the intention of leveraging different opinions and expertise to arrive at a decision that is superior than relying on a single individual.  

The question I'm interested in here is: can we **model** -- and explore under what circumstances -- having more than one decision-maker can result in decisions that improve on those of a single individual?

**Note:** Before posting this, I read around social media and had a look at the literature on MDTs in clinical services particularly mental healthcare.  There are many criticisms of MDTs including the ethics of making decisions about people's care without their involvement (i.e. at the stage of MDTs triaging -- accepting or rejecting -- to specialist teams) -- to be clear, this post does not address these issues in the provision of healthcare in any specialty.  It is more basic and reflects my trying to find a more formal understanding of the commonly-expressed (and widely accepted) view that having a team making decisions results in better decisions.  

## Background
The related theory can be found in [jury theorems](https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem) -- albeit within a judicial framing -- and the oldest result is Condorcet's jury theorem dating back to 1785.  Who knew.  

In machine learning, mixture of experts (MoE) architectures and ensemble learning appeal to the same idea: by combining a collection of imperfect decisions, you can arrive at an overall better decision.

Some basics to get us started:

  * a "jury" (or here, a team) is a collection of individual voters (team members), tasked with arriving at a decision on some issue and each having a **competence** which is the probability they will vote correctly i.e. deliver a "yes" (or "guilty" verdict if you prefer the original framing of juries).  Denote this probability of voting correctly for team member $i$ as $p_i$ but for now we'll assume all voters (MDT members) have equal competence $p_i = p$.   If $p = 0.5$ then each individual voter is no more useful than tossing a coin to arrive at a decision.
  
  * the size of our team (jury) $N$ will always be odd-numbered (3, 5, 7 ...) to avoid tied voting

**Condorcet's jury theorem** is:

  * If $p > 0.5$ -- all voters/team members are more competent than chance -- then increasing the size of the jury (MDT) increases the probability that the majority decision is correct. Further, as the size of the team increases, the probability of a correct majority decision tends to 1
  * For $p \leq 0.5$ -- that is, voters' competence is chance-level or worse -- then increasing the size of the team results in no improvement or a reduction in the probability of a majority correct decision and in these circumstance, the best team is just a single voter.


## Related Literature
A readable introduction to the analysis and philosophy of jury theorems is given in [@dietrich2019jury] which discusses the flaws and assumptions of the framework.  A proof and connection to statistical hypothesis testing is given by [@young1988condorcet].  For some extensions to the basic Condorcet jury theorem, [@ladha1992condorcet] describes how to model voting without independent voter assumptions (i.e. correlated voting) and the relationship with free speech (a little outside the scope of this blog).  Asymptotic results on designing juries with correlated voting are given in [@kaniovski2011optimal] -- see also [the wikipaedia page](https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem) -- but we will not rely on these here, rather we'll use simulations to allow flexibility.

---

# TL;DR -- Yes, Multiple Experts Win

Let's be explicit about the assumptions in the basic Condorcet model [@dietrich2019jury]

  1. Voters are independent (that is, they do not influence one another; there is no "leader" directing the team)
  2. All voters have equal competence


```{r,eval = TRUE, echo = FALSE, cache = TRUE}
N.vals <- seq(1,10,by = 2)
correct.vals <- seq(0.0,1,by = 0.1)

if( RUN_SIMS == TRUE ) {
  df <- expand.grid( N.vals, correct.vals )
  names( df ) <- c("N","pr.Correct")
  df$majority.prob <- NA
  
  for( i in 1:nrow( df ) ) {
    # 1. Build all 2^N voting profiles
    V <- buildVotingMatrix( df$N[i] )
    # 2. Keep only the voting profiles that result in majorities
    #    because those that aren't majorities don't contribute to the sum of probabilities in step 5
    V <- as.data.frame( V[ indexMajority( V ), ] )
    # 3. define uniform voting probability (competence)
    p <- rep(df$pr.Correct[i], df$N[i] )
    # 4. compute probability of each majority voting profile
    pr.v <- computeVotingProfileProb( V, p )
    # 5. sum of majority voting profiles' probabilities
    df$majority.prob[i] <- sum( pr.v )
  }
  save( df, file = "./uniform-competence-results.RData")
} else {
  load( file = "./uniform-competence-results.RData" )
}

```

```{r, eval = TRUE, echo = FALSE}
ggplot( df, aes( x = N, y = majority.prob, colour = as.factor( pr.Correct ) ) ) +
  geom_line() + basictheme + scale_colour_viridis_d(direction = -1, name = "Competence") +
  scale_x_continuous( breaks = seq(1,10,by = 2) ) +
  ylab("Prob. Majority Correct") +
  xlab("Number of Voters")
  
```
In the figure above, we can see that if the competence of voters is chance ($p = 0.5$) then increasing the number of voters has no effect.  If the competence of voters is $p < 0.5$, adding voters makes the team's probability of a correct majority decision **worse**.  And as Condorcet's jury theorem describes, for voters with above-chance competence, the size of the team increase the probability of a correct majority decision. 

So the headline is, for MDTs where each member votes independently and all team members are equally competent above chance-level (all have the same probability of voting correctly), the larger the team, the higher the probability of a majority correct decision.   

The details are given in the [Appendix](#appendix-a)

---

# Mixed Competencies {#mixed}
Not all members of a team will have the same competencies; above, we used uniform competence (i.e. all members of the team voted correctly with the same probability).  In the machine learning literature -- where an MDT or jury is called an ensemble, mixture of experts or a multi-agent system -- "diversity" refers to the agreement between different team members' output [@kuncheva2003measures] and there is an argument that the more diverse the team is, the better the overall performance of the team (however, as Kuncheva and Whittaker show, diversity is hard to formalise).

We can ask a similar, related question about how a mixture of team competencies influence the team's overall probability of arriving at a correct decision. We'll do this by simulating teams of different sizes ($N$) as well as each team member having different voting probabilities (competencies) $p_i$ from a set of possible competences $\Pi = \{ 0.5,0.6,0.7,0.8 \}$.  See the [Appendix](#appendix-b) for details of how we generate the exhaustive set of teams with all combinations of mixed-competencies.

Assume for a team size $N$, the competencies for one possible team are given by a vector or probabilities $\mathbf{p} = (p_1, p_2, \ldots, p_N )$, where each $p_i \in \Pi$.

Define the diversity as:
\begin{align}
  D( \mathbf{p}, N ) &= \sum_{i = 1}^{N} ( p_{max} - p_i ), \\
                     &p_{max} = \max( \mathbf{p})
\end{align}

For example, assume a team of $N=3$ with $\mathbf{p} = (0.5, 0.8, 0.8)$ -- so a team with two highly competent members and one poor performer:

  * $p_{max} = 0.8$
  * $D(\mathbf{p}, N) = (0.8 - 0.5) + (0.8 - 0.8) + (0.8 - 0.8) = 0.3$

And for contrast, a different team of size $N=5$ with $\mathbf{p} = (0.5, 0.5, 0.5, 0.8, 0.8)$ resulting in a diversity of

  * $p_{max} = 0.8$
  * $D(\mathbf{p}, N) = (0.8 - 0.5) + \cdots + (0.8 - 0.8) = 0.9$

Although the team composition is similar (two high performers, the others performing at chance-level), the diversity is three fold larger in the $N=5$ team which makes it difficult to compare.  So, we scale the diversity in the range $[0,1]$:

\begin{align}
  D_{norm}( \mathbf{p}, N ) &= \frac{1}{(N-1)(\Pi_{max} - \Pi_{min})} \sum_{i = 1}^{N} ( p_{max} - p_i ) \\
\end{align}

Where $\Pi_{min}$ and $\Pi_{max}$ are the minimum and maximum possible competencies for any team member (in the simulations here, these are 0.5 and 0.8 respectively).



```{r, eval = TRUE, echo = FALSE}
diversity <- function( p ) {
  p.max <- max(p)
  return( sum( p.max - p ) )
}

diversityMax <- function( p.min, p.max, N ) {
  return(
    (N-1) * (p.max - p.min)
  )
}

modalVal <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

systematicDiversityParams <- function(N, p.i.vals){
  # generate unique UNORDERED tuples of N x p.i.vals
  params <- as.data.frame( RcppAlgos::comboGeneral( p.vals, N, freqs = rep(N,length(p.i.vals)), repetition = FALSE ) )
  # diversity
  c.div <- round( apply( params, 1, diversity ), 2 )
  # median and mode
  c.median <- apply( params, 1, median )

  c.p.max <- apply( params, 1, max )
  # minimum competency in the tuple
  c.p.min <- apply( params, 1, min )
  
  c.sum <- apply( params, 1, sum )
  c.mean <- rowMeans( params )
  
  # measure of unique vals
  c.uni <- apply( params, 1, function(x) { length( unique(x) ) } )

  
  params$diversity <- c.div
  params$p.max <- c.p.max
  params$p.min <- c.p.min
  params$median <- c.median
  params$uni <- c.uni
  params$mean <- c.mean
  params$sum <- c.sum
  
  # remove any tuple with ZERO diversity
  params <- params[ -which( params$diversity == 0 ) ,  ]
  return( params )
}

```



```{r, eval = TRUE, echo = FALSE}
N.vals <- c(3,5,7,9,11)
p.vals <- c(0.5, 0.6, 0.7, 0.8)
  
if( RUN_SIMS == TRUE ) { 
  require(doParallel)
  require(foreach)
  
  cl <- makeCluster(4)
  registerDoParallel(cl)
  
  results <- foreach( i = 1:length(N.vals), .combine = 'c' ) %dopar% {
    # 1. the number of voters in the team
    this.N <- N.vals[i]
    
    # 2. Build a table of systematically varying competencies for this team size
    df <- systematicDiversityParams( this.N, p.vals )
    
    # 3. allocate some space to store majority probability
    df$majority.prob <- rep(NA,nrow(df))
    
    # 4. Build all 2^N voting profiles
    V <- buildVotingMatrix( this.N )
    
    # 5. Keep only the voting profiles that result in majorities
    #    because those that aren't majorities don't contribute to the sum of probabilities in step 6 below
    V <- as.data.frame( V[ indexMajority( V ), ] )
    
    # 6. For each list of team voting probabilities / competencies ...
    for( j in 1:nrow(df) ) {
      p <- df[j,1:this.N]
      #  compute probability of each majority voting profile
      pr.v <- computeVotingProfileProb( V, p )
      #sum of majority voting profiles' probabilities
      df$majority.prob[j] <- sum( pr.v )
    }
    # return df to foreach  
    list(df)
  }
  
  stopCluster(cl)
  save( results, file = "./variable-competence-teams.RData")
  
} else {
  # don't run, instead load old results
  load( file = "./variable-competence-teams.RData" )
}

```

```{r, eval = TRUE, echo = FALSE}

col.pal <- c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854")

plotResult <- function( df, N, anot = NULL ) {
  
  p <- ggplot( df, aes( x = mean, y = majority.prob, colour = factor(p.min), group = factor(p.min) ) ) +
    geom_point() + geom_line() +
    geom_abline( intercept = 0, slope = 1, linetype = "dashed" ) +
    scale_color_manual(values = col.pal, name = "Lowest Member's\nCompetence") +
    basictheme + 
    theme(
      legend.position = c(0.9, 0.2)
    ) +
    ylab("Prob. Majority Correct\n") +
    xlab("\nMean Team Competence") +
    ggtitle(paste0("Team Size = ", N) ) +
    coord_cartesian(
      xlim = c(0.5, max( df$mean) ),
      ylim = c(0.5, 1.0 ),
      expand = TRUE,
      default = FALSE,
      clip = "on"
    )
  
  if( !is.null( anot ) ) {
    p <- p + geom_label( data = anot, aes( x = x1, y = y1, label = labels), inherit.aes = FALSE )
  }
  
  return( p )
}

```
## Small Team Example
To begin with, we simulate a team of size $N=3$ (recall, we use odd $N$ to prevent tied votes).  Each team member has competence (probability of voting correctly) drawn from $p_i \in \{ 0.5, 0.6, 0.7, 0.8 \}$.  Here's a list of all possible team compositions in terms of probabilities of voting correctly (competencies):

```{r, eval = TRUE, echo = FALSE}
ex.comp <- systematicDiversityParams(3, p.vals)
ex.comp <- ex.comp[ , c("V1","V2","V3","diversity", "mean") ]
colnames(ex.comp) <- c("p1","p2","p3", "diversity","mean")
ex.comp <- ex.comp[ order( ex.comp$diversity ), ]
rownames(ex.comp) <- NULL

kbl(ex.comp, caption = "Combinations of Team Competencies") %>% 
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(c(1:3), background  = "#8dd3c7") %>%
  row_spec(c(4:8), background  = "#ffffb3") %>%
  row_spec(c(9:11), background  = "#bebada") %>%
  row_spec(c(12:14), background  = "#fb8072") %>%
  row_spec(c(15:15), background  = "#80b1d3") %>%
  row_spec(c(16:16), background  = "#fdb462")
  
```

Each row is one possible team (mixture of competencies), the three columns (`p1`,`p2` and `p3`) are the voting probabilities of each team member and we have coloured and ordered the rows (teams) by their unscaled diversity.  Finally, we show the arithmetic mean of the team competencies.

The above table establishes all possible team compositions; now, for each row (team) we have to simulate all possible voting profiles and compute the probability of a correct, majority team decision with that team's competencies.

For a concrete example, let's take the first red-coloured row, where we find the vector of competencies is $\mathbf{p} = (0.5, 0.5, 0.7)$ and the diversity is $0.4$.  We now need to compute the probability of this specific team producing a correct majority decision (details are given in the [Appendix](#appendix-b)).

The possible ways each team member can vote in a team of size $N=3$ is:


```{r, echo = FALSE}
N <- 3
V <- buildVotingMatrix(N)

# probability of a "yes" vote
p <- c(0.5,0.5,0.7)
pr.v <- rep(NA, nrow(V))

for( j in 1:nrow(V) ) {
  pr.v[j] <- probVotingProfile( V[j,], p )
}

V$Pr.v <- pr.v

# majority
M <- floor( N / 2 ) + 1

V$One.Votes <- rowSums( V[,1:N] )
V$Majority <- ifelse( V$One.Votes >= M, "Yes", "No" )

kbl(V, caption = "Combinations of Voting Profiles/Patterns") %>% 
  kable_styling(full_width = FALSE, position = "center")
```

Here, the columns `v1`, `v2` and `v3` show how each team member votes (0 or 1).  Each row is one possible pattern or profile of votes and for each row, the column `Majority` shows whether this profile represents a majority voting profile and the column `Pr.v` is the probability of that profile occurring (given that each team member votes independently of the others).  

The probability of a majority correct decision is then the sum of the `Pr.v` column for each row where the voting profile is a majority (i.e. at least two of the three team members vote 1).  We can then state that for a team size of $N=3$, where the team's competence is described by $\mathbf{p} = (0.5, 0.5, 0.7)$, the probability of a majority correct vote from the team is the sum of `Pr.v` for rows 4,6,7 and 8 (those where the `Majority` column is labelled `Yes`) as follows:

$$
0.075 + 0.175 + 0.175 + 0.175 = 0.6
$$

Looking back at Table 3.1, we can see that the probability of a majority vote is larger than the worst performing team members (probability of a correct decision being 0.5), higher than the mean team competence (0.567) but lower that the highest performing team member (0.7).  For this team composition, the team's diversity means we have overall worse performance than it's highest performing individual (i.e. we should leave decision making to the most competent member).  

We want to explore how team diversity (the different competencies) impacts on the team's overall majority decision making, so we have to produce another Table 3.2 for every possible team competence row in Table 3.1.  Then, we repeat the whole process for different sized teams.

RESTART HERE

# Team Diversity and Tolerance for Poorer Performers

Let's now explore how composition of the team can impact performance for a given size of team.


```{r, eval = TRUE, echo = FALSE}
# belowMedian <- function( v ) {
#   M <- median( as.numeric( v ) )
#   return( 
#     length( which( v < M ) )
#   )
# }

new.df <- data.frame()

for( i in 1:length(results) ) {
  df <- results[[i]]
  this.N <- N.vals[ i ]
  
  this.max.D <- diversityMax( min(p.vals), max(p.vals), this.N)
  
  C <- df[,1:this.N]
  # df$N.below.median <- apply( C, 1, belowMedian ) 
  df$N <- this.N
  df$norm.diversity <- df$diversity / this.max.D
  n.cols <- ncol(df)
  new.df <- rbind( new.df, df[,(this.N+1):n.cols] )
}

delta <- 0.01
breaks.prob <- seq(0,1,by = delta )
mid.prob <- breaks.prob[1:(length(breaks.prob)-1)] + delta/2

new.df$majority.prob.bin <- mid.prob[ findInterval( new.df$majority.prob, breaks.prob ) ]



```



```{r, eval = TRUE, echo = FALSE}
ggplot( new.df, aes( y = norm.diversity, x = majority.prob.bin, group = factor( p.max ), colour = factor( p.max ) ) ) +
  geom_point() +
  geom_vline( xintercept = 0.85, colour = "black", linetype = "dashed") +
  facet_wrap( vars(N) ) + basictheme +
  xlab("\n Prob. of Correct Majority Decision") +
  ylab("Diversity\n") 
  # theme(legend.position = "none") 
```



---

# For Another Time ...
Here, we've looked at team composition (diversity of competence), size and asymptotic results (rather than the behaviours of individual teams).   Throughout, we've assumed majority voting rules which is only one way of combining, fusing or synthesizing the outputs of individual team members.  We could -- instead of majority voting decisions -- consider using non-discrete, continuous ways of combining the evidence for a decision among multiple team members but this requires a more granular simulation and model of individuals and team behaviour.

---

# Appendix & Details
## Counting Voting Profiles{#appendix-a}
Designate a jury or MDT (e.g. a group of experts) of $N$ people (jurors, team members), each delivering a vote $v_{i= \{1 \ldots N\}} \in \{0,1\}$ (e.g. innocent/guilty, no/yes to a decision).

Let $\mathbf{V}^N$ be the set of all possible voting profiles for $N$ jurors with size $| \mathbf{V} | = 2^{N}$

For example, with $N = 3$ jurors, we have the following $2^3 = 8$ possible **voting profiles** as follows:


```{r, echo = FALSE}
V <- buildVotingMatrix(N=3)
kbl(V) %>% kable_paper(full_width = TRUE)

```


Let $\mathbf{v}_j \in \mathbf{V}^N$ be a **voting profile** (i.e. a row in the above table) -- for example, $\mathbf{v}_6 = (1,0,1)$

Define a **majority** as $M = \lfloor N/2 \rfloor + 1$.  For example, for $N = 5$ we require a majority of 3 voters/jurors to vote "yes" ("guilty") or one with the remainder voting "no" ("innocent") or zero.

Then, the number of **majority voting profiles** is:

$$
\sum_{k = M}^{N}C(N,k)
$$
Where $C(N,k)$ is the binomial coefficient or $N$ choose $k$, interpreted as $k$ 'one' votes in a jury of size $N$. 

For a jury of $N = 3$, a majority is $M = \lfloor 3/2 \rfloor + 1 = 2$ and we then require all combinations (rows $\mathbf{v}_j \in \mathbf{V}^N$) that have $k=2$ or $k=3$ jurors voting "one":


$$
\begin{align}
C(3,2) + C(3,3) \\
= 3 + 1 \\
= 4
\end{align}
$$

Similarly, for $N=5$ we have:

  * $\mathbf{V}^5$ is the set of all possible voting profiles of size $| \mathbf{V} | = 2^{5} = 32$
  * with a majority of $M = \lfloor 5/2 \rfloor + 1 = 3$
  * and $C(5,3) + C(5,4) + C(5,5) = 16$ majority voting profiles


## Probability of a Voting Profile{#appendix-b}

Each voter $v_i$ is assumed independent (i.e. votes without influence from other members) and a realisation of a Bernoulli trial where the probability of voting "one" ("yes", "guilty" etc) is $\Pr(v_i  = 1) = p_i$ and conversely $\Pr(v_i  = 0) = (1-p_i)$

Consequently, the probability of a given voting profile $\mathbf{v}_j$ -- a single row in the table of all possible voting profiles -- is given by:

$$
  \Pr(\mathbf{v}_j) = \prod_{i=1}^N p_{i}^{v_i} (1-p_{i})^{1-v_i}
$$
For example, with three voters, each voting "yes" with probability being $p_i = p = 0.8$, the probability of the voting profile $\mathbf{v_6} = (1,0,1)$ is:
$$
\begin{align}
 0.8^{1} (1-0.8)^{0} \times 0.8^{0} (1-0.8)^{1} \times 0.8^{1} (1-0.8)^{0} \\
 = 0.8 \times 0.2 \times 0.8 \\
 = 0.128
\end{align}
$$

Let's now look at the complete table of probabilities of voting profiles for $N=3$:

```{r, echo = FALSE}
N <- 3
V <- buildVotingMatrix(N)

# probability of a "yes" vote
p <- c(0.8,0.8,0.8)
pr.v <- rep(NA, nrow(V))

for( j in 1:nrow(V) ) {
  pr.v[j] <- probVotingProfile( V[j,], p )
}

V$Pr.v <- pr.v

# majority
M <- floor( N / 2 ) + 1

V$One.Votes <- rowSums( V[,1:N] )
V$Majority <- ifelse( V$One.Votes >= M, "Yes", "No" )

kbl(V) %>% kable_paper(full_width = TRUE)
```

## Probability of a Majority{#appendix-c}
In the literature on jury theorems, the probability of an individual voting "yes" (guilty, etc.) is called the **competence** of the juror -- so clearly, a voter with $p_i = 0.5$ is no better than chance.

From the set of voting profiles $\mathbf{V}^N$ define a subset $\mathbf{V}_M$ of those profiles that are majorities, that is, where the number of "ones" in the voting profile is greater than or equal to $M$:
$$
  \mathbf{V}_M = \{ \mathbf{v}_j \in \mathbf{v}^N : \sum_{i=1}^{N} v_i \geq M \}
$$
Then the probability of a **majority vote** being correct $\Pr(\mathbf{V}_M)$ is the sum of the probability of each majority voting profile:
$$
  \Pr(\mathbf{V}_M)=\sum_{\mathbf{v}_j \in \mathbf{V}_M}^{} \Pr(\mathbf{v_{j}})
$$
In our simple $N=3$ example above, $\mathbf{V}_M = \{\mathbf{v}_4, \mathbf{v}_6, \mathbf{v}_7, \mathbf{v}_8\}$ and the resulting probability of a majority is $\Pr(\mathbf{V}_M) = 0.128 + 0.128 + 0.128 + 0.512 = 0.896$.  Notice that for the example of $N=3$ and $p_i = p = 0.8$, $\Pr(\mathbf{V}_M) > p$, showing that the probability of obtaining a majority vote is higher than the probability of any individual juror/voter.

## Mixed Competence Teams as Multisets{#appendix-d}
We want to simulate a team of size $N \in \{3,5,7,9,11 \}$ with all possible combinations of a finite set of voting probabilities (competencies) $\Pi = \{ 0.5,0.6,0.7,0.8 \}$.  For example, for $N = 3$, here are four (of many) possible team compositions in terms of competencies:


\begin{align}
  \mathbf{p}_A &= \{ 0.5, 0.5, 0.6\} \\
  \mathbf{p}_B &= \{ 0.5, 0.6, 0.5\} \\
  \mathbf{p}_C &= \{ 0.8, 0.6, 0.5\} \\
  \mathbf{p}_D &= \{ 0.6, 0.6, 0.8\}
\end{align}
  

To be explicit, for $\mathbf{p}_A$ the first and second team member will vote correctly with probability $0.5$ (chance level), and the third member will be correct with probability $0.6$.

For $\mathbf{p}_A$, we note the following quantities:

  * the **minimum competence** is $0.5$ -- that is, the lowest probability of voting correctly amongst the team 
  * the **maximum competence** is $0.6$ -- the highest probability of voting correctly in the team
  * the **mean competence** is approximately $0.53$ -- the arithmetic mean of the team's probability of voting correctly 

For $\mathbf{p}_C$, the minimum, maximum and mean competence is $0.5$, $0.8$ and $0.63$ respectively.  And for $\mathbf{p}_D$, we have minimum, maximum and mean competence of $0.6$, $0.8$ and $0.67$.

Notice that $\mathbf{p}_B$ is a re-ordering of $\mathbf{p}_A$, so the minimum, maximum and mean competence will be the same for both team compositions.  So we don't want to "test" the performance of both $\mathbf{p}_A$ and $\mathbf{p}_B$ because the result will be the same.

This means, we want to generate all **unique** combinations (formally, the [multisets](https://en.wikipedia.org/wiki/Multiset)) of $\Pi$ for any team size $N$.  

Denote the number of different competencies as $\pi = | \Pi |$.  Then, we need to "test" the following number of possible team compositions:

$$
  \frac{(\pi+N-1)!}{N!(\pi-1)!}
$$
As an example, for $N=3$ and $\Pi = \{ 0.5,0.6,0.7,0.8 \}$ where $\pi = 4$ we will need to "test" the performance of $20$ unique team compositions because:
$$
  \frac{(4+3-1)!}{3!(4-1)!} = \frac{6!}{3! \times 3!} = \frac{720}{36} = 20
$$
And for $N=5$ we will need to "test" $56$ multisets, each one representing a unique, unordered composition of a team of size $N$ drawn from $\Pi$.

Finally, note that we already know the behaviour of teams of size $N$ with uniform competence -- for example, for $N=3$, teams with compositions  $\{ 0.5, 0.5, 0.5\}$, $\{ 0.6, 0.6, 0.6\}$, $\{ 0.7, 0.7, 0.7\}$ and $\{ 0.8, 0.8, 0.8\}$ are uninteresting so will we remove them. Generally, there are $\pi$ uniform team compositions to ignore when we run simulations.   


# References
