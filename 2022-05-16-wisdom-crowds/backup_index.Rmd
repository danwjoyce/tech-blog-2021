---
title: Three Heads are Better Than One
author: Dan W. Joyce
date: '2022-05-16'
slug: wisdom-of-crowds
categories: [simulation]
tags: [mixture of experts]
subtitle: 'The Wisdom of Crowds and MDTs'
summary: ''
draft: false
lastmod: '2022-05-15T22:00:06Z'
featured: yes
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []

output:
  blogdown::html_page:
     number_sections: true
     toc: true

header-includes: \usepackage{amsmath}

bibliography: [./biblio.bib]

---

\newcommand{\Var}{\mathrm{Var}}
\newcommand\ci{\perp\!\!\!\perp}


```{r setup, include=FALSE}
rm( list = ls() )
knitr::opts_chunk$set(echo = TRUE)

## Some globals to control execution of chunks because the simulations are
## very time consuming
RUN_SIMS <- FALSE


library(ggplot2)
library(gridExtra)
library(kableExtra)
library(latex2exp)
library(reshape2)
library(viridisLite)
library( RcppAlgos )

# globals for presentation
basictheme <- theme_minimal() + 
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        plot.title = element_text(size = rel(1.25), face = "bold", hjust = 0.5 ))
```

```{r, eval = TRUE, echo = FALSE}

buildVotingMatrix <- function(N) {
  l <- rep(list(0:1), N)
  V <- expand.grid(l)
  names(V) <- paste0( "v", seq(1:N) )
  return(V)
}

probVotingProfile <- function( v, p ) {
  pr.v_i <- 1
  for( i in 1:length( v ) ) {
    pr.v_i <- pr.v_i *
                ( p[i]^v[i] ) * ( 1-p[i] )^(1-v[i] )
  }
  return( as.numeric( pr.v_i ) )
}

computeVotingProfileProb <- function( V, p ) {
  pr.v <- rep(NA, nrow(V))
  N <- ncol(V)
  for( i in 1:nrow(V) ) {
    pr.v[i] <- probVotingProfile( V[i,1:N], p )
  }
  
  return( pr.v ) 
}

indexMajority <- function( V ) {
  N <- ncol(V)
  M <- floor( N/2 ) + 1
  N.ones <- rowSums( V )
  return( which( N.ones >= M ) )
}
  
```


# Introduction
We often make decisions in teams on the assumption that we obtain more reliable decision making when we use the consensus of a group of people -- or to quote C.S. Lewis, "Two heads are better than one, not because either is infallible, but because they are unlikely to go wrong in the same direction".  This is related to the [wisdom of crowds](https://en.wikipedia.org/wiki/Wisdom_of_the_crowd) and is not without controversy.  In healthcare, the multi-disciplinary team (MDT) is central to decision making when there is uncertainty and/or there is a need for multiple expertise; we assemble a group of professionals with the intention of leveraging different opinions and expertise to arrive at a decision that is superior than relying on a single individual.  

The question I'm interested in here is: can we **model** -- and explore under what circumstances -- having more than one decision-maker can result in decisions that improve on those of a single individual?

**Note:** Before posting this, I read around social media and had a look at the literature on MDTs in clinical services particularly mental healthcare.  There are many criticisms of MDTs including the ethics of making decisions about people's care without their involvement (i.e. at the stage of MDTs triaging -- accepting or rejecting -- to specialist teams) -- to be clear, this post does not address these issues in the provision of healthcare in any specialty.  It is more basic and reflects my trying to find a more formal understanding of the commonly-expressed (and widely accepted) view that having a team making decisions results in better decisions.  

## Background
The related theory can be found in [jury theorems](https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem) -- albeit within a judicial framing -- and the oldest result is Condorcet's jury theorem dating back to 1785.  Who knew.  

In machine learning, mixture of experts (MoE) architectures and ensemble learning appeal to the same idea: by combining a collection of imperfect decisions, you can arrive at an overall better decision.

Some basics to get us started:

  * a "jury" (or here, a team) is a collection of individual voters (team members), tasked with arriving at a decision on some issue and each having a **competence** which is the probability they will vote correctly i.e. deliver a "yes" (or "guilty" verdict if you prefer the original framing of juries).  Denote this probability of voting correctly for team member $i$ as $p_i$ but for now we'll assume all voters (MDT members) have equal competence $p_i = p$.   If $p = 0.5$ then each individual voter is no more useful than tossing a coin to arrive at a decision.
  
  * the size of our team (jury) $N$ will always be odd-numbered (3, 5, 7 ...) to avoid tied voting

**Condorcet's jury theorem** is:

  * If $p > 0.5$ -- all voters/team members are more competent than chance -- then increasing the size of the jury (MDT) increases the probability that the majority decision is correct. Further, as the size of the team increases, the probability of a correct majority decision tends to 1
  * For $p \leq 0.5$ -- that is, voters' competence is chance-level or worse -- then increasing the size of the team results in no improvement or a reduction in the probability of a majority correct decision and in these circumstance, the best team is just a single voter.


## Related Literature
A readable introduction to the analysis and philosophy of jury theorems is given in [@dietrich2019jury] which discusses the flaws and assumptions of the framework.  A proof and connection to statistical hypothesis testing is given by [@young1988condorcet].  For some extensions to the basic Condorcet jury theorem, [@ladha1992condorcet] describes how to model voting without independent voter assumptions (i.e. correlated voting) and the relationship with free speech (a little outside the scope of this blog).  Asymptotic results on designing juries with correlated voting are given in [@kaniovski2011optimal] -- see also [the wikipaedia page](https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem) -- but we will not rely on these here, rather we'll use simulations to allow flexibility.

---

# TL;DR -- Yes, Multiple Experts Win

Let's be explicit about the assumptions in the basic Condorcet model [@dietrich2019jury]

  1. Voters are independent (that is, they do not influence one another; there is no "leader" directing the team)
  2. All voters have equal competence


```{r,eval = TRUE, echo = FALSE, cache = TRUE}
N.vals <- seq(1,10,by = 2)
correct.vals <- seq(0.0,1,by = 0.1)

if( RUN_SIMS == TRUE ) {
  df <- expand.grid( N.vals, correct.vals )
  names( df ) <- c("N","pr.Correct")
  df$majority.prob <- NA
  
  for( i in 1:nrow( df ) ) {
    # 1. Build all 2^N voting profiles
    V <- buildVotingMatrix( df$N[i] )
    # 2. Keep only the voting profiles that result in majorities
    #    because those that aren't majorities don't contribute to the sum of probabilities in step 5
    V <- as.data.frame( V[ indexMajority( V ), ] )
    # 3. define uniform voting probability (competence)
    p <- rep(df$pr.Correct[i], df$N[i] )
    # 4. compute probability of each majority voting profile
    pr.v <- computeVotingProfileProb( V, p )
    # 5. sum of majority voting profiles' probabilities
    df$majority.prob[i] <- sum( pr.v )
  }
  save( df, file = "./uniform-competence-results.RData")
} else {
  load( file = "./uniform-competence-results.RData" )
}

```

```{r, eval = TRUE, echo = FALSE}
ggplot( df, aes( x = N, y = majority.prob, colour = as.factor( pr.Correct ) ) ) +
  geom_line() + basictheme + scale_colour_viridis_d(direction = -1, name = "Competence") +
  scale_x_continuous( breaks = seq(1,10,by = 2) ) +
  ylab("Prob. Majority Correct") +
  xlab("Number of Voters")
  
```
In the figure above, we can see that if the competence of voters is chance ($p = 0.5$) then increasing the number of voters has no effect.  If the competence of voters is $p < 0.5$, adding voters makes the team's probability of a correct majority decision **worse**.  And as Condorcet's jury theorem describes, for voters with above-chance competence, the size of the team increase the probability of a correct majority decision. 

So the headline is, for MDTs where each member votes independently and all team members are equally competent above chance-level (all have the same probability of voting correctly), the larger the team, the higher the probability of a majority correct decision.   

The details are given in the [Appendix](#appendix-a)

---

# Mixed Competencies {#mixed}
Not all members of a team will have the same competencies; above, we used uniform competence (i.e. all members of the team voted correctly with the same probability).  In the machine learning literature -- where an MDT or jury is called an ensemble, mixture of experts or a multi-agent system -- "diversity" refers to the agreement between different team members' output [@kuncheva2003measures] and there is an argument that the more diverse the team is, the better the overall performance of the team (however, as Kuncheva and Whittaker show, diversity is hard to formalise).

We can ask a similar, related question about how a mixture of team competencies influence the team's overall probability of arriving at a correct decision. We'll do this by simulating teams of different sizes ($N$) as well as each team member having different voting probabilities (competencies) $p_i$ from a set of possible competences $\Pi = \{ 0.5,0.6,0.7,0.8 \}$.  See the [Appendix](#appendix-b) for details of how we generate the exhaustive set of teams with all combinations of mixed-competencies.

Assume for a team size $N$, the competencies for one possible team are given by a vector or probabilities $\mathbf{p} = (p_1, p_2, \ldots, p_N )$, where each $p_i \in \Pi$.

Define the diversity as:
\begin{align}
  D( \mathbf{p}, N ) &= \sum_{i = 1}^{N} ( p_{max} - p_i ), \\
                     &p_{max} = \max( \mathbf{p})
\end{align}

For example, assume a team of $N=3$ with $\mathbf{p} = (0.5, 0.8, 0.8)$ -- so a team with two highly competent members and one poor performer:

  * $p_{max} = 0.8$
  * $D(\mathbf{p}, N) = (0.8 - 0.5) + (0.8 - 0.8) + (0.8 - 0.8) = 0.3$

And for contrast, a different team of size $N=5$ with $\mathbf{p} = (0.5, 0.5, 0.5, 0.8, 0.8)$ resulting in a diversity of

  * $p_{max} = 0.8$
  * $D(\mathbf{p}, N) = (0.8 - 0.5) + \cdots + (0.8 - 0.8) = 0.9$

Although the team composition is similar (two high performers, the others performing at chance-level), the diversity is three fold larger in the $N=5$ team which makes it difficult to compare.  So, we scale the diversity in the range $[0,1]$:

\begin{align}
  D_{norm}( \mathbf{p}, N ) &= \frac{1}{(N-1)(\Pi_{max} - \Pi_{min})} \sum_{i = 1}^{N} ( p_{max} - p_i ) \\
\end{align}

Where $\Pi_{min}$ and $\Pi_{max}$ are the minimum and maximum possible competencies for any team member (in the simulations here, these are 0.5 and 0.8 respectively).



```{r, eval = TRUE, echo = FALSE}
diversity <- function( p ) {
  p.max <- max(p)
  return( sum( p.max - p ) )
}

diversityMax <- function( p.min, p.max, N ) {
  return(
    (N-1) * (p.max - p.min)
  )
}

modalVal <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

systematicDiversityParams <- function(N, p.i.vals){
  # generate unique UNORDERED tuples of N x p.i.vals
  params <- as.data.frame( RcppAlgos::comboGeneral( p.vals, N, freqs = rep(N,length(p.i.vals)), repetition = FALSE ) )
  # diversity
  c.div <- round( apply( params, 1, diversity ), 2 )
  # median and mode
  c.median <- apply( params, 1, median )

  c.p.max <- apply( params, 1, max )
  # minimum competency in the tuple
  c.p.min <- apply( params, 1, min )
  
  c.sum <- apply( params, 1, sum )
  c.mean <- rowMeans( params )
  
  # measure of unique vals
  c.uni <- apply( params, 1, function(x) { length( unique(x) ) } )

  
  params$diversity <- c.div
  params$p.max <- c.p.max
  params$p.min <- c.p.min
  params$median <- c.median
  params$uni <- c.uni
  params$mean <- c.mean
  params$sum <- c.sum
  
  # remove any tuple with ZERO diversity
  params <- params[ -which( params$diversity == 0 ) ,  ]
  return( params )
}

```



```{r, eval = TRUE, echo = FALSE}
N.vals <- c(3,5,7,9,11)
p.vals <- c(0.5, 0.6, 0.7, 0.8)
  
if( RUN_SIMS == TRUE ) { 
  require(doParallel)
  require(foreach)
  
  cl <- makeCluster(4)
  registerDoParallel(cl)
  
  results <- foreach( i = 1:length(N.vals), .combine = 'c' ) %dopar% {
    # 1. the number of voters in the team
    this.N <- N.vals[i]
    
    # 2. Build a table of systematically varying competencies for this team size
    df <- systematicDiversityParams( this.N, p.vals )
    
    # 3. allocate some space to store majority probability
    df$majority.prob <- rep(NA,nrow(df))
    
    # 4. Build all 2^N voting profiles
    V <- buildVotingMatrix( this.N )
    
    # 5. Keep only the voting profiles that result in majorities
    #    because those that aren't majorities don't contribute to the sum of probabilities in step 6 below
    V <- as.data.frame( V[ indexMajority( V ), ] )
    
    # 6. For each list of team voting probabilities / competencies ...
    for( j in 1:nrow(df) ) {
      p <- df[j,1:this.N]
      #  compute probability of each majority voting profile
      pr.v <- computeVotingProfileProb( V, p )
      #sum of majority voting profiles' probabilities
      df$majority.prob[j] <- sum( pr.v )
    }
    # return df to foreach  
    list(df)
  }
  
  stopCluster(cl)
  save( results, file = "./variable-competence-teams.RData")
  
} else {
  # don't run, instead load old results
  load( file = "./variable-competence-teams.RData" )
}

```

```{r, eval = TRUE, echo = FALSE}

col.pal <- c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854")

plotResult <- function( df, N, anot = NULL ) {
  
  p <- ggplot( df, aes( x = mean, y = majority.prob, colour = factor(p.min), group = factor(p.min) ) ) +
    geom_point() + geom_line() +
    geom_abline( intercept = 0, slope = 1, linetype = "dashed" ) +
    scale_color_manual(values = col.pal, name = "Lowest Member's\nCompetence") +
    basictheme + 
    theme(
      legend.position = c(0.9, 0.2)
    ) +
    ylab("Prob. Majority Correct\n") +
    xlab("\nMean Team Competence") +
    ggtitle(paste0("Team Size = ", N) ) +
    coord_cartesian(
      xlim = c(0.5, max( df$mean) ),
      ylim = c(0.5, 1.0 ),
      expand = TRUE,
      default = FALSE,
      clip = "on"
    )
  
  if( !is.null( anot ) ) {
    p <- p + geom_label( data = anot, aes( x = x1, y = y1, label = labels), inherit.aes = FALSE )
  }
  
  return( p )
}

```
## Small Team Example
To begin with, we simulate a team of size $N=3$ (recall, we use odd $N$ to prevent tied votes).  Each team member has competence (probability of voting correctly) $p_i \in \{ 0.5, 0.6, 0.7, 0.8 \}$.  Here's a list of all possible team compositions in terms of probabilities of voting correctly (competencies):

```{r, eval = TRUE, echo = FALSE}
ex.comp <- systematicDiversityParams(3, p.vals)
ex.comp <- ex.comp[ , c("V1","V2","V3","diversity", "mean") ]
colnames(ex.comp) <- c("p1","p2","p3", "diversity","mean")
ex.comp <- ex.comp[ order( ex.comp$diversity ), ]
rownames(ex.comp) <- NULL

kbl(ex.comp) %>% 
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(c(1:3), background  = "#8dd3c7") %>%
  row_spec(c(4:8), background  = "#ffffb3") %>%
  row_spec(c(9:11), background  = "#bebada") %>%
  row_spec(c(12:14), background  = "#fb8072") %>%
  row_spec(c(15:15), background  = "#80b1d3") %>%
  row_spec(c(16:16), background  = "#fdb462")
  
```
The three columns (`p1`,`p2` and `p3`) are the voting probabilities of each team member.  We have coloured and ordered the rows (teams) by their unscaled diversity.  Finally, we show the arithmetic mean of the team competencies.

```RESTART HERE```

The rows are coloured by `p.min`.  We have labelled four team compositions for special attention (A,B,C and D):

  * Team A has the following competencies $\{0.5,0.5,0.6\}$ -- so, two of the team members perform at chance level (equally likely to vote correctly or incorrectly) and one team member performs at $0.6$, just above chance level.  The arithmetic mean (average) competency of team A is approximately $0.53$ so overall, it's a poorly performing team
  * Team B has composition $\{0.5, 0.8, 0.8\}$ -- here, the team is dominated by very high performing members (i.e. two members will vote correctly with probability $0.8$) but the lowest performing team member performs at chance-level only.  The average team competence is $0.7$ so overall, a high-performing team, with one poor performer
  * Team C is composed as $\{0.6,0.6,0.7\}$ -- overall, a modest-performing team with mean approximately $0.633$ and one member performing better than the others ($0.7$) with the other two at $0.6$.
  * Team D is composed as $\{0.7,0.8,0.8\}$ -- overall, a high-performing team, with average competence approximately $0.766$ with two very high performers ($0.8$) and one team member slightly lagging at $0.7$.  Team D is the best possible performing team, with the exception of a uniformly-high performing team with composition $\{0.8, 0.8, 0.8\}$ -- but we've already seen how these uniform teams perform so we won't consider them further because here we're concerned with mixed-performance teams.

For every different combination of team member competencies, we now compute the probability of the team arriving at the correct majority decision, plotting this on the vertical axis of a plot.  We will plot the team's average (mean) competence on the horizontal, and then "group" and colour by the worst performing team member (`p.min` in the table above).   

Here's what we find, for the case where we have a team size $N=3$:


```{r, eval = TRUE, echo = FALSE}

label.points <- 
  data.frame(
    x1 = c(0.53, 0.7, 0.633, 0.77),
    y1 = c(0.60, 0.85, 0.66, 0.9),
    labels = c("A","B","C", "D")
  )

this.result <- results[[1]]

plotResult( this.result, N = 3, anot = label.points )


```

This graph shows us how the the worst performing member of a team affects the probability of the team *collectively* arriving at the correct majority decision but requires some explanation. 

  * the dotted line illustrates the case where the probability of a majority correct decision is no better than the average (mean) team competence -- for example, for Team A with mean competence approximately $0.53$, and generally, poor performance (two of the team members perform at chance level, whereas one member is correct with probability $0.6$) we see that in a majority vote, the team is correct overall with probability $0.55$ -- higher than the worse performing team members, higher than the average competence of the team and slightly lower than the highest performing individual in the team.

  * for Team C with composition $\{0.6,0.6,0.7\}$ -- a team with a modest mean competence at approximately $0.633$ -- the team's probability of a majority vote being correct is $0.696$.  Again better than the average team competence.  Of note, if we interrogate the results table (below), we find that Team C has slightly lower majority performance as teams with competencies $\{0.5, 0.6, 0.8 \}$ and $\{0.5, 0.7, 0.7\}$ which both achieve majority correct decisions with probability $0.7$.  So, having some diversity in a small team (a range of competencies from very low to high) can be helpful.
  
```{r, eval = TRUE, echo = FALSE}
ex.res <- results[[1]]
ex.res$name <- rep("",nrow(ex.comp))
ex.res$name[c(1,9,10,16)] <- c("A","B","C","D")

ex.res.display <- ex.res[ which( round( ex.res$mean, 3) == 0.633), c("V1","V2","V3","p.min","mean","majority.prob","name") ]
colnames(ex.res.display) <- c("p1","p2","p3","p.min","mean","majority.prob","name")
rownames(ex.res.display) <- NULL

kable(ex.res.display, "html") %>%  kable_styling(full_width = FALSE, position = "center")
```

  * Team B has composition $\{0.5, 0.8,0.8 \}$ (an excellent team, with one poor performer) and Team D has composition $\{0.7,0.8,0.8\}$ (an excellent team, with one member performing slightly worse).  Let's look at the results for the 5 teams with the best majority probabilities -- the teams between and including B and D on the graph:  RETURN TO THIS
  
```{r, eval = TRUE, echo = FALSE}
ex.res.display2 <- ex.res[ order(ex.res$majority.prob, decreasing = TRUE ), c("V1","V2","V3","p.min","mean","majority.prob","name") ]

ex.res.display2 <- ex.res.display2[1:5,]
colnames(ex.res.display2) <- c("p1","p2","p3","p.min","mean","majority.prob","name")
rownames(ex.res.display2) <- NULL

kable(ex.res.display2, "html") %>%  kable_styling(full_width = FALSE, position = "center")
```
## Larger, More Diverse Teams
It's hard to have much diversity of competence in a team of three people.

```{r, eval = TRUE, echo = FALSE}

# label.points <- 
#   data.frame(
#     x1 = c(0.53, 0.7, 0.633, 0.77),
#     y1 = c(0.60, 0.85, 0.66, 0.9),
#     labels = c("A","B","C", "D")
#   )

this.result <- results[[2]]

p3 <- plotResult( results[[1]], N = 3 )
p5 <- plotResult( results[[2]], N = 5 )
p11 <- plotResult( results[[5]], N = 11 )
print( p3 )
```
```{r, eval = TRUE, echo = FALSE}
print(p5)
```

```{r, eval = TRUE, echo = FALSE}
print(p11)
```

Things get more interesting when we compare teams of size $N=3$, $N=5$ and $N=11$.  In the graphs above, we see that as the team size increases, for any given mean team competence, we obtain higher probabilities of a majority correct decision.  For example, if we pull the team's majority probability correct for all teams with competences of 0.6 and 0.7:

```{r, eval = TRUE, echo = FALSE}
df.3 <- round( results[[1]], 3 )
df.5 <- round( results[[2]], 3 )
df.11 <- round( results[[5]], 3 )

df.3 <- df.3[ order( df.3$mean ), ]
df.5 <- df.5[ order( df.5$mean ), ]
df.11 <- df.11[ order( df.11$mean ), ]


t3_0.6 <- which( df.3$mean == 0.6 )
t5_0.6 <- which( df.5$mean == 0.6 )
t11_0.6 <- which( df.11$mean == 0.6 )

t3_0.7 <- which( df.3$mean == 0.7 )
t5_0.7 <- which( df.5$mean == 0.7 )
t11_0.7 <- which( df.11$mean == 0.7 )

df.res <- rbind(  
  cbind( N = 3, df.3[ t3_0.6, c("p.min","mean","median", "majority.prob") ] ),
  cbind( N = 3, df.3[ t3_0.7, c("p.min","mean","median", "majority.prob") ] ),
  cbind( N = 5, df.5[ t5_0.6, c("p.min","mean","median", "majority.prob") ] ),
  cbind( N = 5, df.5[ t5_0.7, c("p.min","mean","median", "majority.prob") ] ),
  cbind( N = 11, df.11[ t11_0.6, c("p.min","mean","median", "majority.prob") ] ),
  cbind( N = 11, df.11[ t11_0.7, c("p.min","mean","median", "majority.prob") ] )
)
```

```{r, eval = TRUE, echo = FALSE}
ggplot( df.res, aes( x = factor(N), y = majority.prob, colour = factor(mean) ) ) + 
  geom_point(size = 2.0) +
  geom_jitter( width = 0.3, height = 0.0 ) + 
  scale_color_manual(values = col.pal, name = "Mean Team\nCompetence") +
  # scale_x_continuous(name ="Team Size",
  #                  breaks = c(3,4,5),
  #                  labels = c("3","","5")) +
  ylab("Prob. Majority Correct\n") +
  xlab("\nTeam Size (N)") +
  basictheme
```
We've added a small amount of horizontal jitter and coloured the points by the mean team competence.  Predictably, teams with higher mean competence perform better and this gain scales with the team size.

These analyses average over different team compositions which are essentially indexed by the arithmetic mean of the team's competence and we've grouped (coloured) teams by the "worst performing" team member.  

# Team Diversity and Tolerance for Poorer Performers

Let's now explore how composition of the team can impact performance for a given size of team.


```{r, eval = TRUE, echo = FALSE}
# belowMedian <- function( v ) {
#   M <- median( as.numeric( v ) )
#   return( 
#     length( which( v < M ) )
#   )
# }

new.df <- data.frame()

for( i in 1:length(results) ) {
  df <- results[[i]]
  this.N <- N.vals[ i ]
  
  this.max.D <- diversityMax( min(p.vals), max(p.vals), this.N)
  
  C <- df[,1:this.N]
  # df$N.below.median <- apply( C, 1, belowMedian ) 
  df$N <- this.N
  df$norm.diversity <- df$diversity / this.max.D
  n.cols <- ncol(df)
  new.df <- rbind( new.df, df[,(this.N+1):n.cols] )
}

delta <- 0.01
breaks.prob <- seq(0,1,by = delta )
mid.prob <- breaks.prob[1:(length(breaks.prob)-1)] + delta/2

new.df$majority.prob.bin <- mid.prob[ findInterval( new.df$majority.prob, breaks.prob ) ]



```



```{r, eval = TRUE, echo = FALSE}
ggplot( new.df, aes( y = norm.diversity, x = majority.prob.bin, group = factor( p.max ), colour = factor( p.max ) ) ) +
  geom_point() +
  geom_vline( xintercept = 0.85, colour = "black", linetype = "dashed") +
  facet_wrap( vars(N) ) + basictheme +
  xlab("\n Prob. of Correct Majority Decision") +
  ylab("Diversity\n") 
  # theme(legend.position = "none") 
```



---

# For Another Time ...
Here, we've looked at team composition (diversity of competence), size and asymptotic results (rather than the behaviours of individual teams).   Throughout, we've assumed majority voting rules which is only one way of combining, fusing or synthesizing the outputs of individual team members.  We could -- instead of majority voting decisions -- consider using non-discrete, continuous ways of combining the evidence for a decision among multiple team members but this requires a more granular simulation and model of individuals and team behaviour.

---

# Appendix & Details
## Counting Voting Profiles{#appendix-a}
Designate a jury or MDT (e.g. a group of experts) of $N$ people (jurors, team members), each delivering a vote $v_{i= \{1 \ldots N\}} \in \{0,1\}$ (e.g. innocent/guilty, no/yes to a decision).

Let $\mathbf{V}^N$ be the set of all possible voting profiles for $N$ jurors with size $| \mathbf{V} | = 2^{N}$

For example, with $N = 3$ jurors, we have the following $2^3 = 8$ possible **voting profiles** as follows:


```{r, echo = FALSE}
V <- buildVotingMatrix(N=3)
kbl(V) %>% kable_paper(full_width = TRUE)

```


Let $\mathbf{v}_j \in \mathbf{V}^N$ be a **voting profile** (i.e. a row in the above table) -- for example, $\mathbf{v}_6 = (1,0,1)$

Define a **majority** as $M = \lfloor N/2 \rfloor + 1$.  For example, for $N = 5$ we require a majority of 3 voters/jurors to vote "yes" ("guilty") or one with the remainder voting "no" ("innocent") or zero.

Then, the number of **majority voting profiles** is:

$$
\sum_{k = M}^{N}C(N,k)
$$
Where $C(N,k)$ is the binomial coefficient or $N$ choose $k$, interpreted as $k$ 'one' votes in a jury of size $N$. 

For a jury of $N = 3$, a majority is $M = \lfloor 3/2 \rfloor + 1 = 2$ and we then require all combinations (rows $\mathbf{v}_j \in \mathbf{V}^N$) that have $k=2$ or $k=3$ jurors voting "one":


$$
\begin{align}
C(3,2) + C(3,3) \\
= 3 + 1 \\
= 4
\end{align}
$$

Similarly, for $N=5$ we have:

  * $\mathbf{V}^5$ is the set of all possible voting profiles of size $| \mathbf{V} | = 2^{5} = 32$
  * with a majority of $M = \lfloor 5/2 \rfloor + 1 = 3$
  * and $C(5,3) + C(5,4) + C(5,5) = 16$ majority voting profiles


## Probability of a Voting Profile

Each voter $v_i$ is assumed independent (i.e. votes without influence from other members) and a realisation of a Bernoulli trial where the probability of voting "one" ("yes", "guilty" etc) is $\Pr(v_i  = 1) = p_i$ and conversely $\Pr(v_i  = 0) = (1-p_i)$

Consequently, the probability of a given voting profile $\mathbf{v}_j$ -- a single row in the table of all possible voting profiles -- is given by:

$$
  \Pr(\mathbf{v}_j) = \prod_{i=1}^N p_{i}^{v_i} (1-p_{i})^{1-v_i}
$$
For example, with three voters, each voting "yes" with probability being $p_i = p = 0.8$, the probability of the voting profile $\mathbf{v_6} = (1,0,1)$ is:
$$
\begin{align}
 0.8^{1} (1-0.8)^{0} \times 0.8^{0} (1-0.8)^{1} \times 0.8^{1} (1-0.8)^{0} \\
 = 0.8 \times 0.2 \times 0.8 \\
 = 0.128
\end{align}
$$

Let's now look at the complete table of probabilities of voting profiles for $N=3$:

```{r, echo = FALSE}
N <- 3
V <- buildVotingMatrix(N)

# probability of a "yes" vote
p <- c(0.8,0.8,0.8)
pr.v <- rep(NA, nrow(V))

for( j in 1:nrow(V) ) {
  pr.v[j] <- probVotingProfile( V[j,], p )
}

V$Pr.v <- pr.v

# majority
M <- floor( N / 2 ) + 1

V$One.Votes <- rowSums( V[,1:N] )
V$Majority <- ifelse( V$One.Votes >= M, "Yes", "No" )

kbl(V) %>% kable_paper(full_width = TRUE)

```

## Probability of a Majority
In the literature on jury theorems, the probability of an individual voting "yes" (guilty, etc.) is called the **competence** of the juror -- so clearly, a voter with $p_i = 0.5$ is no better than chance.

From the set of voting profiles $\mathbf{V}^N$ define a subset $\mathbf{V}_M$ of those profiles that are majorities, that is, where the number of "ones" in the voting profile is greater than or equal to $M$:
$$
  \mathbf{V}_M = \{ \mathbf{v}_j \in \mathbf{v}^N : \sum_{i=1}^{N} v_i \geq M \}
$$
Then the probability of a **majority vote** being correct $\Pr(\mathbf{V}_M)$ is the sum of the probability of each majority voting profile:
$$
  \Pr(\mathbf{V}_M)=\sum_{\mathbf{v}_j \in \mathbf{V}_M}^{} \Pr(\mathbf{v_{j}})
$$
In our simple $N=3$ example above, $\mathbf{V}_M = \{\mathbf{v}_4, \mathbf{v}_6, \mathbf{v}_7, \mathbf{v}_8\}$ and the resulting probability of a majority is $\Pr(\mathbf{V}_M) = 0.128 + 0.128 + 0.128 + 0.512 = 0.896$.  Notice that for the example of $N=3$ and $p_i = p = 0.8$, $\Pr(\mathbf{V}_M) > p$, showing that the probability of obtaining a majority vote is higher than the probability of any individual juror/voter.

## Mixed Competence Teams as Multisets{#appendix-b}
We want to simulate a team of size $N \in \{3,5,7,9,11 \}$ with all possible combinations of a finite set of voting probabilities (competencies) $\Pi = \{ 0.5,0.6,0.7,0.8 \}$.  For example, for $N = 3$, here are four (of many) possible team compositions in terms of competencies:


\begin{align}
  \mathbf{p}_A &= \{ 0.5, 0.5, 0.6\} \\
  \mathbf{p}_B &= \{ 0.5, 0.6, 0.5\} \\
  \mathbf{p}_C &= \{ 0.8, 0.6, 0.5\} \\
  \mathbf{p}_D &= \{ 0.6, 0.6, 0.8\}
\end{align}
  

To be explicit, for $\mathbf{p}_A$ the first and second team member will vote correctly with probability $0.5$ (chance level), and the third member will be correct with probability $0.6$.

For $\mathbf{p}_A$, we note the following quantities:

  * the **minimum competence** is $0.5$ -- that is, the lowest probability of voting correctly amongst the team 
  * the **maximum competence** is $0.6$ -- the highest probability of voting correctly in the team
  * the **mean competence** is approximately $0.53$ -- the arithmetic mean of the team's probability of voting correctly 

For $\mathbf{p}_C$, the minimum, maximum and mean competence is $0.5$, $0.8$ and $0.63$ respectively.  And for $\mathbf{p}_D$, we have minimum, maximum and mean competence of $0.6$, $0.8$ and $0.67$.

Notice that $\mathbf{p}_B$ is a re-ordering of $\mathbf{p}_A$, so the minimum, maximum and mean competence will be the same for both team compositions.  So we don't want to "test" the performance of both $\mathbf{p}_A$ and $\mathbf{p}_B$ because the result will be the same.

This means, we want to generate all **unique** combinations (formally, the [multisets](https://en.wikipedia.org/wiki/Multiset)) of $\Pi$ for any team size $N$.  

Denote the number of different competencies as $\pi = | \Pi |$.  Then, we need to "test" the following number of possible team compositions:

$$
  \frac{(\pi+N-1)!}{N!(\pi-1)!}
$$
As an example, for $N=3$ and $\Pi = \{ 0.5,0.6,0.7,0.8 \}$ where $\pi = 4$ we will need to "test" the performance of $20$ unique team compositions because:
$$
  \frac{(4+3-1)!}{3!(4-1)!} = \frac{6!}{3! \times 3!} = \frac{720}{36} = 20
$$
And for $N=5$ we will need to "test" $56$ multisets, each one representing a unique, unordered composition of a team of size $N$ drawn from $\Pi$.

Finally, note that we already know the behaviour of teams of size $N$ with uniform competence -- for example, for $N=3$, teams with compositions  $\{ 0.5, 0.5, 0.5\}$, $\{ 0.6, 0.6, 0.6\}$, $\{ 0.7, 0.7, 0.7\}$ and $\{ 0.8, 0.8, 0.8\}$ are uninteresting so will we remove them. Generally, there are $\pi$ uniform team compositions to ignore when we run simulations.   


# References
