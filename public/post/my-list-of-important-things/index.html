<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Dan W Joyce" />

  
  
  
    
  
  <meta name="description" content="1 Purpose 2 Posterior Predictive Distributions  2.1 Conditional Probability 2.2 Law of Total Probability 2.3 Conditional Independence 2.4 Bayes Theorem 2.5 Bayes with Extra Conditioning 2.6 Deriving the PPD  3 Sampling and Integration 4 Logits, Probabilities and Odds  4." />

  
  <link rel="alternate" hreflang="en-us" href="/post/my-list-of-important-things/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.ddb2a9c79d7760a321f1b5392a04566a.css" />

  



  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hub05f02e644906e3d80c1c494250cac2e_12120_32x32_fill_lanczos_center_2.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hub05f02e644906e3d80c1c494250cac2e_12120_180x180_fill_lanczos_center_2.png" />

  <link rel="canonical" href="/post/my-list-of-important-things/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
    <meta property="twitter:site" content="@@dan_w_joyce" />
    <meta property="twitter:creator" content="@@dan_w_joyce" />
  
  <meta property="og:site_name" content="Dan W Joyce" />
  <meta property="og:url" content="/post/my-list-of-important-things/" />
  <meta property="og:title" content="Stuff I Always Look Up ... | Dan W Joyce" />
  <meta property="og:description" content="1 Purpose 2 Posterior Predictive Distributions  2.1 Conditional Probability 2.2 Law of Total Probability 2.3 Conditional Independence 2.4 Bayes Theorem 2.5 Bayes with Extra Conditioning 2.6 Deriving the PPD  3 Sampling and Integration 4 Logits, Probabilities and Odds  4." /><meta property="og:image" content="/media/icon_hub05f02e644906e3d80c1c494250cac2e_12120_512x512_fill_lanczos_center_2.png" />
    <meta property="twitter:image" content="/media/icon_hub05f02e644906e3d80c1c494250cac2e_12120_512x512_fill_lanczos_center_2.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2021-11-05T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2021-11-05T22:05:06&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/my-list-of-important-things/"
  },
  "headline": "Stuff I Always Look Up ...",
  
  "datePublished": "2021-11-05T00:00:00Z",
  "dateModified": "2021-11-05T22:05:06Z",
  
  "author": {
    "@type": "Person",
    "name": "dwj"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Dan W Joyce",
    "logo": {
      "@type": "ImageObject",
      "url": "/media/icon_hub05f02e644906e3d80c1c494250cac2e_12120_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "1 Purpose 2 Posterior Predictive Distributions  2.1 Conditional Probability 2.2 Law of Total Probability 2.3 Conditional Independence 2.4 Bayes Theorem 2.5 Bayes with Extra Conditioning 2.6 Deriving the PPD  3 Sampling and Integration 4 Logits, Probabilities and Odds  4."
}
</script>

  

  

  

  





  <title>Stuff I Always Look Up ... | Dan W Joyce</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="34f4781f02fd8887872eec7fa652af2d" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.f16be01fc8fb2b5885dd67ce942d1185.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Dan W Joyce</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Dan W Joyce</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://twitter.com/dan_w_joyce" data-toggle="tooltip" data-placement="bottom" title="Follow me on Twitter" target="_blank" rel="noopener" aria-label="Follow me on Twitter">
              <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
          </li>
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Stuff I Always Look Up ...</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/author/dwj/">dwj</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Nov 5, 2021
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/computation/">computation</a>, <a href="/category/maths/">maths</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      


<div id="TOC">
<ul>
<li><a href="#purpose"><span class="toc-section-number">1</span> Purpose</a></li>
<li><a href="#posterior-predictive-distributions"><span class="toc-section-number">2</span> Posterior Predictive Distributions</a>
<ul>
<li><a href="#conditional-probability"><span class="toc-section-number">2.1</span> Conditional Probability</a></li>
<li><a href="#law-of-total-probability"><span class="toc-section-number">2.2</span> Law of Total Probability</a></li>
<li><a href="#conditional-independence"><span class="toc-section-number">2.3</span> Conditional Independence</a></li>
<li><a href="#bayes-theorem"><span class="toc-section-number">2.4</span> Bayes Theorem</a></li>
<li><a href="#bayes-with-extra-conditioning"><span class="toc-section-number">2.5</span> Bayes with Extra Conditioning</a></li>
<li><a href="#deriving-the-ppd"><span class="toc-section-number">2.6</span> Deriving the PPD</a></li>
</ul></li>
<li><a href="#sampling-and-integration"><span class="toc-section-number">3</span> Sampling and Integration</a></li>
<li><a href="#logits-probabilities-and-odds"><span class="toc-section-number">4</span> Logits, Probabilities and Odds</a>
<ul>
<li><a href="#odds"><span class="toc-section-number">4.1</span> Odds</a></li>
<li><a href="#odds-ratios"><span class="toc-section-number">4.2</span> Odds Ratios</a></li>
<li><a href="#logistic-regression"><span class="toc-section-number">4.3</span> Logistic Regression</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="purpose" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Purpose</h1>
<p>This is a living, annotated bibliography of stuff I need to use on a semi-regular basis, always have to look up but in my chaotic file system, can never find. It also documents some embarrassing truths – stuff like <em>“Is variance the square root of standard deviation, or the other way round?”</em> … Of course, it’s the other way round.</p>
<p>So, point number one: If <span class="math inline">\(\sigma_X\)</span> is the standard deviation of <span class="math inline">\(X\)</span> then:
<span class="math display">\[
\mathrm{Var}(X) = \sigma^2_X
\]</span></p>
</div>
<div id="posterior-predictive-distributions" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Posterior Predictive Distributions</h1>
<p>I spent a week trying to find a derivation of equation 1.4 on pp.7 of <span class="citation">(<a href="#ref-gelman2014bayesian" role="doc-biblioref">Gelman et al. 2014</a>)</span>, the posterior predictive distribution <span class="citation">(<a href="#ref-rubin1984bayesianly" role="doc-biblioref">Rubin 1984</a>)</span> of new data <span class="math inline">\(\tilde{y}\)</span> given previously observed data <span class="math inline">\(y\)</span> and a model with parameters <span class="math inline">\(\theta\)</span>
<span class="math display" id="eq:PPD">\[\begin{equation}
p( \tilde{y} | y ) = \int p\left( \tilde{y} | \theta \right) p\left( \theta | y \right)  d\theta \tag{2.1}
\label{eqn:finalPPD}
\end{equation}\]</span></p>
<p>There are explanations floating around on the internet, but none I could follow because they skipped steps and left me confused.</p>
<p>We need a few basic laws and definitions from probability theory as follows <span class="citation">(<a href="#ref-blitzstein2014introduction" role="doc-biblioref">Blitzstein and Hwang 2019</a>)</span>:</p>
<div id="conditional-probability" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Conditional Probability</h2>
<p>For two variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>:
<span class="math display" id="eq:condprob">\[\begin{equation}
p(a | b) = \frac{p(a,b)}{p(b)} \tag{2.2}
\end{equation}\]</span></p>
<p>Or re-arranged:
<span class="math display" id="eq:condprob2">\[\begin{equation}
p(a,b) = p(a | b) p(b) \tag{2.3}
\end{equation}\]</span></p>
<p>And for two variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, conditioned on <span class="math inline">\(c\)</span>:
<span class="math display" id="eq:condprob3">\[\begin{equation}
p(a,b | c) = \frac{p(a,b,c)}{p(c)} \tag{2.4}
\end{equation}\]</span></p>
<p>and the re-arrangement:
<span class="math display">\[\begin{equation}
p(a,b,c) =  p(a,b | c) p(c)
\end{equation}\]</span></p>
<p>Note that <span class="math inline">\(p(a,b,c)\)</span> can also be factorised as <em>any</em> of the following (depending on what we want to achieve):
<span class="math display" id="eq:factors3" id="eq:factors2" id="eq:factors1">\[\begin{align}
  p(a,b,c) &amp;= p(b,c|a) p(a) \tag{2.5} \\
          &amp;= p(a,c|b) p(b) \tag{2.6} \\
          &amp;= p(a,b|c) p(c) \tag{2.7}
\end{align}\]</span></p>
</div>
<div id="law-of-total-probability" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Law of Total Probability</h2>
<p>From the joint probability <span class="math inline">\(p(a,b)\)</span>, the marginal <span class="math inline">\(p(a)\)</span> is:
<span class="math display">\[\begin{equation}
p(a) = \int p \left( a, b \right) db
\end{equation}\]</span></p>
<p>And the continuous <em>law of total probability</em> is <span class="citation">(<a href="#ref-blitzstein2014introduction" role="doc-biblioref">Blitzstein and Hwang 2019</a>)</span> pp. 289:
<span class="math display" id="eq:lotp2">\[\begin{align}
p(a) &amp;= \int p \left( a,b \right) db \\
     &amp;= \int p \left( a|b \right) p( b )db \tag{2.8}
\end{align}\]</span></p>
<p>where we’ve used equation <a href="#eq:condprob2">(2.3)</a> to re-write <span class="math inline">\(p \left( a,b \right)\)</span> as <span class="math inline">\(p \left( a|b \right) p( b )\)</span></p>
<p>Adding conditioning on <span class="math inline">\(c\)</span> we obtain <span class="citation">(<a href="#ref-blitzstein2014introduction" role="doc-biblioref">Blitzstein and Hwang 2019</a>)</span> pp. 54:
<span class="math display" id="eq:lotp-cond">\[\begin{align}
\label{eqn:lotp_cont}
p \left( a|c \right) &amp;= \int p \left( a,b | c \right) db \\
                     &amp;= \int p \left( a|b,c \right) p( b | c ) db \tag{2.9}
\end{align}\]</span></p>
</div>
<div id="conditional-independence" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Conditional Independence</h2>
<p>Two variables <span class="math inline">\(a\)</span> and <span class="math inline">\(c\)</span> are <em>conditionally independent</em> given a third variable <span class="math inline">\(b\)</span> <span class="citation">(<a href="#ref-blitzstein2014introduction" role="doc-biblioref">Blitzstein and Hwang 2019</a>)</span> pp. 58:
<span class="math display" id="eq:condind1">\[\begin{equation}
( a \perp\!\!\!\perp c ) | b \iff p(a,c | b) = p( a | b ) p( c | b) \tag{2.10}
\end{equation}\]</span></p>
</div>
<div id="bayes-theorem" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Bayes Theorem</h2>
<p>For two variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>:
<span class="math display" id="eq:bayes">\[\begin{equation}
p(a|b) = \frac{p(b|a)p(a)}{p(b)} \tag{2.11}
\end{equation}\]</span></p>
</div>
<div id="bayes-with-extra-conditioning" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Bayes with Extra Conditioning</h2>
<p>I frequently have to remind myself how to rewrite this form: <span class="math inline">\(p(a | b, c)\)</span> – this is covered in <span class="citation">(<a href="#ref-blitzstein2014introduction" role="doc-biblioref">Blitzstein and Hwang 2019</a>)</span> Theorem 2.4.2 on pp. 54-56.</p>
<p>There are a few useful ways to re-write.</p>
<p><strong>Using Conditional Probability</strong></p>
<p>Assume it makes sense (in the problem we’re trying to solve) to view <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> as “one thing together” then using the formula for conditional probability we get:
<span class="math display" id="eq:bayesrewritecond">\[\begin{equation}
  p( a | b, c ) = \frac{p(a,b,c)}{p(b,c)}  \tag{2.12}
\end{equation}\]</span></p>
<p>Applying conditional probability again – equation <a href="#eq:condprob3">(2.4)</a> and the different factorisations in <a href="#eq:factors1">(2.5)</a> through <a href="#eq:factors3">(2.7)</a> – to rewrite <span class="math inline">\(p(a,b,c)\)</span>:
<span class="math display">\[\begin{align}
  p(a,b,c) &amp;= p(b,c|a) p(a)  \\
          &amp;= p(a,c|b) p(b)  \\
          &amp;= p(a,b|c) p(c)
\end{align}\]</span></p>
<p>Choosing the RHS as suited to the problem - here, we take <span class="math inline">\(p(b,c|a) p(a)\)</span> as we are treating <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> as “one event” (we want to keep them together) and substitute in <a href="#eq:bayesrewritecond">(2.12)</a>:
<span class="math display" id="eq:bayesrewritecond2">\[\begin{equation}
  p( a | b, c ) = \frac{ p(b,c|a) p(a) }{ p( b,c ) } \tag{2.13}
\end{equation}\]</span></p>
<p>Now, we have to find an expression for the denominator <span class="math inline">\(p( b,c )\)</span> and we have options including another application of conditional probability so <span class="math inline">\(p( b, c ) = p(b|c) p(c)\)</span> resulting in:
<span class="math display" id="eq:bayesrewritecond2">\[\begin{equation}
  p( a | b, c ) = \frac{ p(b,c|a) p(a) }{ p(b|c) p(c) } \tag{2.13}
\end{equation}\]</span></p>
<p><strong>Using the Chain Rule of Probability</strong></p>
<p>Start, as before, with:
<span class="math display" id="eq:bayesrewritecond3">\[\begin{equation}
  p( a | b, c ) = \frac{p(a,b,c)}{p(b,c)} \tag{2.14}
\end{equation}\]</span></p>
<p>This time, decompose <span class="math inline">\(p(a,b,c)\)</span> differently, using the chain rule:
<span class="math display">\[\begin{align}
  p(a,b,c) &amp;= p(a|b,c)p(b,c)  \\
           &amp;= p(b|a,c)p(a,c)  \\
           &amp;= p(c|a,b)p(a,b)
\end{align}\]</span>
Obviously, the first re-write gets us nowhere – it merely restates <span class="math inline">\(p(a|b,c)\)</span>. Lets say the second factorisation is helpful for our problem <span class="math inline">\(p(b|a,c)p(a,c)\)</span>, then we substitute in <a href="#eq:bayesrewritecond3">(2.14)</a>:</p>
<p><span class="math display" id="eq:bayesrewritecond4">\[\begin{equation}
  p( a | b, c ) = \frac{p(b|a,c)p(a,c)}{p(b,c)} \tag{2.15}
\end{equation}\]</span></p>
<p>We now have to deal with <span class="math inline">\(p(a,c)\)</span> in the numerator and <span class="math inline">\(p(b,c)\)</span> in the denominator. Starting with the numerator, apply conditional probability again:
<span class="math display">\[\begin{equation}
  p( a, c ) = p(a|c)p(c)
\end{equation}\]</span></p>
<p>For the denominator:
<span class="math display">\[\begin{equation}
  p( b, c ) = p(b|c)p(c)
\end{equation}\]</span></p>
<p>What we end up with is Bayes theorem with extra conditioning on <span class="math inline">\(c\)</span> …</p>
<p><strong>Bayes Theorem with Extra Conditioning on <span class="math inline">\(c\)</span></strong></p>
<p>Substitute both into <a href="#eq:bayesrewritecond4">(2.15)</a>:
<span class="math display">\[\begin{align}
  p( a | b, c ) &amp;= \frac{p(b|a,c) p(a|c)p(c)} {p(b|c)p(c)} \\
                &amp;= \frac{p(b|a,c) p(a|c)} {p(b|c)}
\end{align}\]</span></p>
<p><strong>Bayes Theorem with Extra Conditioning on <span class="math inline">\(b\)</span></strong></p>
<p>Had we chosen, instead, to use <span class="math inline">\(p(c|a,b)p(a,b)\)</span>, we end up with:
<span class="math display">\[\begin{align}
  p( a | b, c ) &amp;= \frac{p(a,b,c)}{p(b,c)} \\
                &amp;= \frac{p(c|a,b)p(a,b)}{p(b,c)}
\end{align}\]</span></p>
<p>with <span class="math inline">\(p(a,b) = p(a|b)p(b)\)</span>:
<span class="math display">\[\begin{equation}
  p( a | b, c ) = \frac{p(c|a,b)p(a|b)p(b)}{p(b,c)}
\end{equation}\]</span></p>
<p>Of course, <span class="math inline">\(p(b,c) = p(c,b) = p(c|b)p(b)\)</span> in the denominator:
<span class="math display">\[\begin{align}
  p( a | b, c ) &amp;= \frac{p(c|a,b)p(a|b)p(b)}{p(c|b)p(b)} \\
                &amp;= \frac{p(c|a,b)p(a|b)}{p(c|b)}
\end{align}\]</span></p>
<p>We chose between conditioning on <span class="math inline">\(c\)</span> or <span class="math inline">\(b\)</span> depending on the problem we are trying to solve (i.e. does it make sense to consider everything being conditioned on <span class="math inline">\(c\)</span> or <span class="math inline">\(b\)</span> ?)</p>
</div>
<div id="deriving-the-ppd" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Deriving the PPD</h2>
<p>Starting with the fundamental Bayesian modelling framework:</p>
<ol style="list-style-type: decimal">
<li>before observing the data, <span class="math inline">\(y\)</span>, the <em>prior distribution</em> of the parameters is <span class="math inline">\(p(\theta)\)</span></li>
<li>we have a <em>sampling distribution</em> of the data <em>given</em> parameters <span class="math inline">\(p(y|\theta)\)</span></li>
<li>the joint distribution of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(y\)</span> is <span class="math inline">\(p(\theta, y) = p(\theta)p(y|\theta)\)</span></li>
<li>we then obtain the <em>posterior distribution</em> of the parameters of the model given the observed data:</li>
</ol>
<p><span class="math display">\[\begin{equation}
    p(\theta|y) = \frac{p(\theta,y)}{p(y)} = \frac{p(\theta)p(y|\theta)}{p(y)}
\end{equation}\]</span></p>
<p>So, we can think of the posterior distribution <span class="math inline">\(p(\theta|y)\)</span> as the `output’ of Bayesian model estimation.</p>
<p><strong>Step 1</strong></p>
<p>We want to obtain a distribution for future values <span class="math inline">\(\tilde{y}\)</span> given the observed (and modelled) data <span class="math inline">\(y\)</span> which is <span class="math inline">\(p(\tilde{y}|y)\)</span> using what we know about the posterior distribution arising from parameter estimation <span class="math inline">\(p(\theta | y)\)</span>.</p>
<p>The first step is to write <span class="math inline">\(p(\tilde{y}|y)\)</span> using the law of total probability (with conditioning): equation <a href="#eq:lotp-cond">(2.9)</a>:
<span class="math display" id="eq:step1">\[\begin{equation}
    p( \tilde{y} | y ) = \int p\left(\tilde{y},\theta | y \right) d\theta \tag{2.16}
\end{equation}\]</span></p>
<p><strong>Step 2</strong></p>
<p>Re-write the integrand <span class="math inline">\(p\left(\tilde{y},\theta | y \right)\)</span> using equation <a href="#eq:condprob3">(2.4)</a>:</p>
<p><span class="math display" id="eq:step2">\[\begin{equation}
    p( \tilde{y} | y ) = \int \frac{p(\tilde{y},\theta,y)}{p(y)} d\theta \tag{2.17}
\end{equation}\]</span></p>
<p><strong>Step 3</strong></p>
<p>We assert that <span class="math inline">\(\tilde{y}\)</span> is conditionally independent of <span class="math inline">\(y\)</span> <em>given</em> the model parameters <span class="math inline">\(\theta\)</span>:
<span class="math display" id="eq:condind-ppd">\[\begin{equation}
  ( \tilde{y} \perp\!\!\!\perp y ) | \theta \iff p( \tilde{y}, y | \theta) = p( \tilde{y} | \theta ) p( y | \theta) \tag{2.18}
\end{equation}\]</span></p>
<p>To make use of the conditional independence <span class="math inline">\(p( \tilde{y}, y | \theta)\)</span>, we have to factorise <span class="math inline">\(p(\tilde{y},\theta,y)\)</span> in equation <a href="#eq:step2">(2.17)</a>.</p>
<p>Let <span class="math inline">\(a = \tilde{y}\)</span>, <span class="math inline">\(b = \theta\)</span> and <span class="math inline">\(c = y\)</span>; we are seeking a factorisation of <span class="math inline">\(p(a,b,c)\)</span> as <span class="math inline">\(p(a,c|b)\)</span> and inspecting the factorisations <a href="#eq:factors1">(2.5)</a> through <a href="#eq:factors3">(2.7)</a> we find that <a href="#eq:factors2">(2.6)</a> matches:</p>
<p><span class="math display" id="eq:factor-cond-ind">\[\begin{align}
  p(a,b,c) &amp;= p(a,c|b) p(b) \\
  p( \tilde{y}, \theta, y) &amp;= p( \tilde{y}, y | \theta) p(\theta) \tag{2.19}
\end{align}\]</span></p>
<p>Substitution <a href="#eq:factor-cond-ind">(2.19)</a> into <a href="#eq:step2">(2.17)</a> we have:</p>
<p><span class="math display" id="eq:step3a">\[\begin{equation}
p(\tilde{y} | y ) = \int \frac{p(\tilde{y},y | \theta) p(\theta)}{p(y)} d \theta \tag{2.20}
\end{equation}\]</span></p>
<p>We make use of the equality from equation <a href="#eq:condind-ppd">(2.18)</a> i.e. that <span class="math inline">\(p( \tilde{y}, y | \theta) = p( \tilde{y} | \theta ) p( y | \theta)\)</span> and substitute into <a href="#eq:step3a">(2.20)</a>:</p>
<p><span class="math display" id="eq:step3b">\[\begin{equation}
p(\tilde{y} | y ) = \int \frac{ p( \tilde{y} | \theta ) p( y | \theta)  p(\theta)}{p(y)} d \theta \tag{2.21}
\end{equation}\]</span></p>
<p><strong>Step 4</strong></p>
<p>Recall that we want to make use of the ‘output’ of parameter estimation, the posterior distribution of the model parameters given the observed data <span class="math inline">\(p(\theta|y)\)</span>, and in equation <a href="#eq:step3b">(2.21)</a> we see the term <span class="math inline">\(p(y|\theta)\)</span>. All we need to do is re-write <span class="math inline">\(p(y|\theta)\)</span> using Bayes rule, equation <a href="#eq:bayes">(2.11)</a>:</p>
<p><span class="math display">\[\begin{equation}
p(y|\theta) = \frac{p(\theta|y) p(y)}{p(\theta)}
\end{equation}\]</span></p>
<p>And substitute into equation <a href="#eq:step3b">(2.21)</a>:
<span class="math display" id="eq:step4">\[\begin{align}
p(\tilde{y} | y ) &amp;= \int \frac{ p( \tilde{y} | \theta ) p(\theta|y) p(y)   p(\theta)}{p(y)p(\theta)} d \theta  \\
                  &amp;= \int p( \tilde{y} | \theta ) p(\theta|y) d \theta \tag{2.22} \\

\end{align}\]</span></p>
<p>… and there we have it, the expression for the PPD, equation <a href="#eq:PPD">(2.1)</a></p>
</div>
</div>
<div id="sampling-and-integration" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Sampling and Integration</h1>
<p>This one came from <a href="https://twitter.com/ChadScherrer">Chad Scherrer</a> who posted a <a href="https://twitter.com/ChadScherrer/status/1292528021568552962?s=20">tweet</a> about the relationship between integration and sampling and I thought this was a really helpful heuristic.</p>
<p>When I work through examples of Bayesian problems, my first thought is “<strong>how will I code this?</strong>” and Chad’s tweet comes to mind, and helpfully, it follows nicely from the posterior predictive distribution example.</p>
<p>To paraphrase Chad’s tweet:</p>
<ul>
<li>To sample from <span class="math inline">\(p(y|x)p(x)\)</span> …
<ol style="list-style-type: decimal">
<li>Sample <span class="math inline">\(x\)</span></li>
<li>Use the sample of <span class="math inline">\(x\)</span> to sample <span class="math inline">\(y\)</span></li>
<li>Return <span class="math inline">\((x,y)\)</span></li>
</ol></li>
<li>To sample from <span class="math inline">\(\int p(y|x)p(x) dx\)</span> …
<ol style="list-style-type: decimal">
<li>Sample <span class="math inline">\(x\)</span></li>
<li>Use the sample of <span class="math inline">\(x\)</span> to sample <span class="math inline">\(y\)</span></li>
<li>Discard <span class="math inline">\(x\)</span></li>
<li>Return <span class="math inline">\(y\)</span></li>
</ol></li>
</ul>
<p>In practice then: we want to obtain samples from the <em>posterior predictive distribution</em> <span class="math inline">\(p(\tilde{y}|y)\)</span> i.e. for some new or unseen <span class="math inline">\(\tilde{x}\)</span>.</p>
<p><span class="math display">\[\begin{equation}
p(\tilde{y} | y ) = \int p( \tilde{y} | \theta ) p(\theta|y) d \theta
\end{equation}\]</span></p>
<p>Here’s how to proceed. We’ve used some Bayesian parameter estimation method (e.g. MCMC or similar) to obtain samples from <span class="math inline">\(p(\theta|y)\)</span> and stored them as <span class="math inline">\(\Theta_S\)</span></p>
<p>We have a function that returns a value <span class="math inline">\(\tilde{y}\)</span> given an input <span class="math inline">\(\tilde{x}\)</span> and parameters <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(\tilde{y} = f(\tilde{x}; \theta)\)</span></p>
<p>For each sample <span class="math inline">\(\theta^{s} \in \Theta_S\)</span> – one sample from <span class="math inline">\(p(\theta|y)\)</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Compute <span class="math inline">\(\tilde{y}^s = f(\tilde{x}; \theta^{s})\)</span> – a sample from <span class="math inline">\(p(\tilde{y}|\theta)\)</span></p></li>
<li><p>Store <span class="math inline">\(\tilde{y}^s\)</span> and throw away <span class="math inline">\(\theta^{s}\)</span></p></li>
</ol>
<p>Our resulting collection of <span class="math inline">\(\tilde{y}^s\)</span> are samples from the PPD from which we can then take expected values, quantiles etc.</p>
</div>
<div id="logits-probabilities-and-odds" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Logits, Probabilities and Odds</h1>
<p>Can never remember these relations, so wrote them down explicitly for future reference.</p>
<div id="odds" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Odds</h2>
<p>If <span class="math inline">\(p_A\)</span> is the probability of event <span class="math inline">\(A\)</span> then:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\textrm{odds}_A = \frac{1}{(1-p_A)}\)</span></li>
<li>given the odds, we recover the probability as <span class="math inline">\(p_A = \frac{\textrm{odds}_A}{1+\textrm{odds}_A}\)</span></li>
<li>the <strong>log odds</strong> are given by <span class="math inline">\(\ln(\textrm{odds}_A) = \ln \left( \frac{1}{1-p_A} \right) = \textrm{logit}(p_A) = \ln(p_A) - \ln(1-p_A)\)</span></li>
</ol>
<p>So, odds of 1.0 equals a probability <span class="math inline">\(p_A = 0.5\)</span> – the probability of the event occurring is at chance level.</p>
</div>
<div id="odds-ratios" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Odds Ratios</h2>
<p>For two events, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> with probabilities <span class="math inline">\(p_A\)</span> and <span class="math inline">\(p_B\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\textrm{odds}_A = \frac{1}{(1-p_A)}\)</span> and <span class="math inline">\(\textrm{odds}_B = \frac{1}{(1-p_B)}\)</span></li>
<li>the <strong>odds ratio</strong> <span class="math inline">\(\textrm{OR}_{AB} = \frac{\textrm{odds}_A}{\textrm{odds}_B} = \frac{1-p_B}{1-p_A}\)</span></li>
</ol>
</div>
<div id="logistic-regression" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Logistic Regression</h2>
<p>In logistic regression applied to clinical situations, we are usually interested in a single “thing” associated with two discrete and mutually-exclusive events (e.g. <span class="math inline">\(A\)</span> = “dying” or <span class="math inline">\(B\)</span> = “not dying”) – the thing either occurs or it does <em>not</em> occur. In these circumstances <span class="math inline">\(p_B = 1 - p_A\)</span>.</p>
<p>To convert to the language of regression, denote an outcome <span class="math inline">\(y\)</span> (for example, death, experiencing a side effect, obtaining a positive response to a treatment) then:</p>
<ol style="list-style-type: decimal">
<li>the probability that <span class="math inline">\(y\)</span> occurred is <span class="math inline">\(p_y\)</span> (equivalent to <span class="math inline">\(p_A\)</span> in the example above)</li>
<li>the corresponding probability <span class="math inline">\(y\)</span> <strong>does not</strong> occur (<span class="math inline">\(¬y\)</span>) is <span class="math inline">\(1-p_y\)</span> (equivalent to <span class="math inline">\(p_B\)</span> in the example above)</li>
<li>the odds of <span class="math inline">\(y\)</span> occurring are <span class="math inline">\(\textrm{odds}_{y} = \frac{1}{(1-p_y)}\)</span> and the odds of <span class="math inline">\(¬y\)</span> are <span class="math inline">\(\textrm{odds}_{¬y} = \frac{1}{1-(1-p_y)} = \frac{1}{p_y}\)</span></li>
<li>the odds ratio of <span class="math inline">\(y\)</span> and <span class="math inline">\(¬y\)</span> is then <span class="math inline">\(\textrm{OR}_{(y,¬y)} = \frac{p_y}{1-p_y}\)</span></li>
</ol>
<p>Further reading: Chapter 13 of <span class="citation">(<a href="#ref-gelman2020regression" role="doc-biblioref">Gelman, Hill, and Vehtari 2020</a>)</span> walks through all this with examples and code in R. On the web, Jay Rotella has a <a href="https://www.montana.edu/rotella/documents/502/Prob_odds_log-odds.pdf">nice PDF walk through</a> of the same material with elaboration and graphical examples in R.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-blitzstein2014introduction" class="csl-entry">
Blitzstein, Joseph K, and Jessica Hwang. 2019. <em>Introduction to Probability</em>. 2nd ed. Chapman; Hall/CRC.
</div>
<div id="ref-gelman2020regression" class="csl-entry">
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. <em>Regression and Other Stories</em>. Cambridge University Press.
</div>
<div id="ref-gelman2014bayesian" class="csl-entry">
Gelman, Andrew, Hal S Stern, John B Carlin, David B Dunson, Aki Vehtari, and Donald B Rubin. 2014. <em>Bayesian Data Analysis</em>. 3rd ed. Chapman; Hall/CRC.
</div>
<div id="ref-rubin1984bayesianly" class="csl-entry">
Rubin, Donald B. 1984. <span>“Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician.”</span> <em>The Annals of Statistics</em> 12 (4): 1151–72.
</div>
</div>
</div>

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/probability/">probability</a>
  
  <a class="badge badge-light" href="/tag/regression/">regression</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/my-list-of-important-things/&amp;text=Stuff%20I%20Always%20Look%20Up%20..." target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/my-list-of-important-things/&amp;t=Stuff%20I%20Always%20Look%20Up%20..." target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Stuff%20I%20Always%20Look%20Up%20...&amp;body=/post/my-list-of-important-things/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/my-list-of-important-things/&amp;title=Stuff%20I%20Always%20Look%20Up%20..." target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Stuff%20I%20Always%20Look%20Up%20...%20/post/my-list-of-important-things/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/my-list-of-important-things/&amp;title=Stuff%20I%20Always%20Look%20Up%20..." target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    




  














  
  





  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.71e713848164e269bc250f377042949d.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
